{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Optimizing Redshift Table Design"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:55:55.340761Z",
     "start_time": "2025-06-30T15:55:54.389702Z"
    }
   },
   "source": [
    "from time import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import redshift_connector"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Get the params of the created redshift cluster \n",
    "1. Tạo 1 Redshift cluster rồi lấy Endpoint (bỏ phần cuối `:5439/`) điền vào file `dwh.cfg`\n",
    "\n",
    "<img src=\"images/aws1.png\" width=1000>\n",
    "\n",
    "2. Tạo 1 IAM role rồi lấy ARN điền vào file `dwh.cfg`\n",
    "\n",
    "<img src=\"images/aws2.png\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Connect to the Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:14:07.530688Z",
     "start_time": "2025-06-30T16:14:07.524816Z"
    }
   },
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dwh.cfg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:56:10.392949Z",
     "start_time": "2025-06-30T15:56:00.996538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = redshift_connector.connect(\n",
    "    host=config['CLUSTER']['HOST'],\n",
    "    database=config['CLUSTER']['DB_NAME'],\n",
    "    port=config['CLUSTER']['DB_PORT'],\n",
    "    user=config['CLUSTER']['DB_USER'],\n",
    "    password=config['CLUSTER']['DB_PASSWORD']\n",
    ")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 3: Create Tables\n",
    "- We are going to use a benchmarking data set common for benchmarking star schemas in data warehouses.\n",
    "- The data is pre-loaded in a public bucket on the `us-west-2` region\n",
    "- Our examples will be based on the Amazon Redshfit tutorial but in a scripted environment in our workspace.\n",
    "\n",
    "![afa](https://docs.aws.amazon.com/redshift/latest/dg/images/tutorial-optimize-tables-ssb-data-model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.1. Create tables (no distribution strategy) in the `nodist` schema"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:59:37.578585Z",
     "start_time": "2025-06-30T15:59:29.393414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cur.execute(\"CREATE SCHEMA IF NOT EXISTS nodist;\")\n",
    "cur.execute(\"SET search_path TO nodist;\")\n",
    "\n",
    "cur.execute(\"DROP TABLE IF EXISTS part cascade;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS supplier;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS supplier;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS customer;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS dwdate;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS lineorder;\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE part\n",
    "    (\n",
    "      p_partkey     INTEGER NOT NULL,\n",
    "      p_name        VARCHAR(22) NOT NULL,\n",
    "      p_mfgr        VARCHAR(6) NOT NULL,\n",
    "      p_category    VARCHAR(7) NOT NULL,\n",
    "      p_brand1      VARCHAR(9) NOT NULL,\n",
    "      p_color       VARCHAR(11) NOT NULL,\n",
    "      p_type        VARCHAR(25) NOT NULL,\n",
    "      p_size        INTEGER NOT NULL,\n",
    "      p_container   VARCHAR(10) NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE supplier\n",
    "    (\n",
    "      s_suppkey   INTEGER NOT NULL,\n",
    "      s_name      VARCHAR(25) NOT NULL,\n",
    "      s_address   VARCHAR(25) NOT NULL,\n",
    "      s_city      VARCHAR(10) NOT NULL,\n",
    "      s_nation    VARCHAR(15) NOT NULL,\n",
    "      s_region    VARCHAR(12) NOT NULL,\n",
    "      s_phone     VARCHAR(15) NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE customer\n",
    "    (\n",
    "      c_custkey      INTEGER NOT NULL,\n",
    "      c_name         VARCHAR(25) NOT NULL,\n",
    "      c_address      VARCHAR(25) NOT NULL,\n",
    "      c_city         VARCHAR(10) NOT NULL,\n",
    "      c_nation       VARCHAR(15) NOT NULL,\n",
    "      c_region       VARCHAR(12) NOT NULL,\n",
    "      c_phone        VARCHAR(15) NOT NULL,\n",
    "      c_mktsegment   VARCHAR(10) NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE dwdate\n",
    "    (\n",
    "      d_datekey            INTEGER NOT NULL,\n",
    "      d_date               VARCHAR(19) NOT NULL,\n",
    "      d_dayofweek          VARCHAR(10) NOT NULL,\n",
    "      d_month              VARCHAR(10) NOT NULL,\n",
    "      d_year               INTEGER NOT NULL,\n",
    "      d_yearmonthnum       INTEGER NOT NULL,\n",
    "      d_yearmonth          VARCHAR(8) NOT NULL,\n",
    "      d_daynuminweek       INTEGER NOT NULL,\n",
    "      d_daynuminmonth      INTEGER NOT NULL,\n",
    "      d_daynuminyear       INTEGER NOT NULL,\n",
    "      d_monthnuminyear     INTEGER NOT NULL,\n",
    "      d_weeknuminyear      INTEGER NOT NULL,\n",
    "      d_sellingseason      VARCHAR(13) NOT NULL,\n",
    "      d_lastdayinweekfl    VARCHAR(1) NOT NULL,\n",
    "      d_lastdayinmonthfl   VARCHAR(1) NOT NULL,\n",
    "      d_holidayfl          VARCHAR(1) NOT NULL,\n",
    "      d_weekdayfl          VARCHAR(1) NOT NULL\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE lineorder\n",
    "    (\n",
    "      lo_orderkey          INTEGER NOT NULL,\n",
    "      lo_linenumber        INTEGER NOT NULL,\n",
    "      lo_custkey           INTEGER NOT NULL,\n",
    "      lo_partkey           INTEGER NOT NULL,\n",
    "      lo_suppkey           INTEGER NOT NULL,\n",
    "      lo_orderdate         INTEGER NOT NULL,\n",
    "      lo_orderpriority     VARCHAR(15) NOT NULL,\n",
    "      lo_shippriority      VARCHAR(1) NOT NULL,\n",
    "      lo_quantity          INTEGER NOT NULL,\n",
    "      lo_extendedprice     INTEGER NOT NULL,\n",
    "      lo_ordertotalprice   INTEGER NOT NULL,\n",
    "      lo_discount          INTEGER NOT NULL,\n",
    "      lo_revenue           INTEGER NOT NULL,\n",
    "      lo_supplycost        INTEGER NOT NULL,\n",
    "      lo_tax               INTEGER NOT NULL,\n",
    "      lo_commitdate        INTEGER NOT NULL,\n",
    "      lo_shipmode          VARCHAR(10) NOT NULL\n",
    "    );\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x7243e7899570>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.2. Create tables (with a distribution strategy) in the `dist` schema"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:08:51.112549Z",
     "start_time": "2025-06-30T16:08:43.252045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cur.execute(\"CREATE SCHEMA IF NOT EXISTS dist;\")\n",
    "cur.execute(\"SET search_path TO dist;\")\n",
    "\n",
    "cur.execute(\"DROP TABLE IF EXISTS part cascade;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS supplier;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS supplier;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS customer;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS dwdate;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS lineorder;\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE part (\n",
    "  p_partkey     \tinteger     \tnot null\tsortkey distkey,\n",
    "  p_name        \tvarchar(22) \tnot null,\n",
    "  p_mfgr        \tvarchar(6)      not null,\n",
    "  p_category    \tvarchar(7)      not null,\n",
    "  p_brand1      \tvarchar(9)      not null,\n",
    "  p_color       \tvarchar(11) \tnot null,\n",
    "  p_type        \tvarchar(25) \tnot null,\n",
    "  p_size        \tinteger     \tnot null,\n",
    "  p_container   \tvarchar(10)     not null\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE supplier (\n",
    "  s_suppkey     \tinteger        not null sortkey,\n",
    "  s_name        \tvarchar(25)    not null,\n",
    "  s_address     \tvarchar(25)    not null,\n",
    "  s_city        \tvarchar(10)    not null,\n",
    "  s_nation      \tvarchar(15)    not null,\n",
    "  s_region      \tvarchar(12)    not null,\n",
    "  s_phone       \tvarchar(15)    not null)\n",
    "diststyle all;\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE customer (\n",
    "  c_custkey     \tinteger        not null sortkey,\n",
    "  c_name        \tvarchar(25)    not null,\n",
    "  c_address     \tvarchar(25)    not null,\n",
    "  c_city        \tvarchar(10)    not null,\n",
    "  c_nation      \tvarchar(15)    not null,\n",
    "  c_region      \tvarchar(12)    not null,\n",
    "  c_phone       \tvarchar(15)    not null,\n",
    "  c_mktsegment      varchar(10)    not null)\n",
    "diststyle all;\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE dwdate (\n",
    "  d_datekey            integer       not null sortkey,\n",
    "  d_date               varchar(19)   not null,\n",
    "  d_dayofweek\t      varchar(10)   not null,\n",
    "  d_month      \t    varchar(10)   not null,\n",
    "  d_year               integer       not null,\n",
    "  d_yearmonthnum       integer  \t not null,\n",
    "  d_yearmonth          varchar(8)\tnot null,\n",
    "  d_daynuminweek       integer       not null,\n",
    "  d_daynuminmonth      integer       not null,\n",
    "  d_daynuminyear       integer       not null,\n",
    "  d_monthnuminyear     integer       not null,\n",
    "  d_weeknuminyear      integer       not null,\n",
    "  d_sellingseason      varchar(13)    not null,\n",
    "  d_lastdayinweekfl    varchar(1)    not null,\n",
    "  d_lastdayinmonthfl   varchar(1)    not null,\n",
    "  d_holidayfl          varchar(1)    not null,\n",
    "  d_weekdayfl          varchar(1)    not null)\n",
    "diststyle all;\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE lineorder (\n",
    "  lo_orderkey      \t    integer     \tnot null,\n",
    "  lo_linenumber        \tinteger     \tnot null,\n",
    "  lo_custkey           \tinteger     \tnot null,\n",
    "  lo_partkey           \tinteger     \tnot null distkey,\n",
    "  lo_suppkey           \tinteger     \tnot null,\n",
    "  lo_orderdate         \tinteger     \tnot null sortkey,\n",
    "  lo_orderpriority     \tvarchar(15)     not null,\n",
    "  lo_shippriority      \tvarchar(1)      not null,\n",
    "  lo_quantity          \tinteger     \tnot null,\n",
    "  lo_extendedprice     \tinteger     \tnot null,\n",
    "  lo_ordertotalprice   \tinteger     \tnot null,\n",
    "  lo_discount          \tinteger     \tnot null,\n",
    "  lo_revenue           \tinteger     \tnot null,\n",
    "  lo_supplycost        \tinteger     \tnot null,\n",
    "  lo_tax               \tinteger     \tnot null,\n",
    "  lo_commitdate         integer         not null,\n",
    "  lo_shipmode          \tvarchar(10)     not null\n",
    ");\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x7243e7899570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 4: Copying tables \n",
    "\n",
    "Our intent here is to run 5 COPY operations for the 5 tables respectively as show below.\n",
    "\n",
    "However, we want to do accomplish the following:\n",
    "- Make sure that the `DWH_ROLE_ARN` is substituted with the correct value in each query\n",
    "- Perform the data loading twice once for each schema (dist and nodist)\n",
    "- Collect timing statistics to compare the insertion times\n",
    "Thus, we have scripted the insertion as found below in the function `loadTables` which\n",
    "returns a pandas dataframe containing timing statistics for the copy operations\n",
    "\n",
    "```sql\n",
    "copy customer from 's3://awssampledbuswest2/ssbgz/customer' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy dwdate from 's3://awssampledbuswest2/ssbgz/dwdate' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy lineorder from 's3://awssampledbuswest2/ssbgz/lineorder' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy part from 's3://awssampledbuswest2/ssbgz/part' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy supplier from 's3://awssampledbuswest2/ssbgz/supplier' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Automate  the copying"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:14:11.190022Z",
     "start_time": "2025-06-30T16:14:11.185571Z"
    }
   },
   "source": [
    "def loadTables(schema, tables):\n",
    "    loadTimes = []\n",
    "    SQL_SET_SCEMA = \"SET search_path TO {};\".format(schema)\n",
    "    cur.execute(SQL_SET_SCEMA)\n",
    "    \n",
    "    for table in tables:\n",
    "        SQL_COPY = \"\"\"\n",
    "            copy {} from 's3://awssampledbuswest2/ssbgz/{}'\n",
    "            credentials 'aws_iam_role={}'\n",
    "            gzip region 'us-west-2';\n",
    "        \"\"\".format(table, table, config['IAM_ROLE']['ARN'])\n",
    "\n",
    "        print(\"======= LOADING TABLE: ** {} ** IN SCHEMA ==> {} =======\".format(table, schema))\n",
    "        print(SQL_COPY)\n",
    "\n",
    "        t0 = time()\n",
    "        cur.execute(SQL_COPY)\n",
    "        loadTime = time()-t0\n",
    "        loadTimes.append(loadTime)\n",
    "\n",
    "        print(\"=== DONE IN: {0:.2f} sec\\n\".format(loadTime))\n",
    "    return pd.DataFrame({\"table\":tables, \"loadtime_\"+schema:loadTimes}).set_index('table')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:43:58.142246Z",
     "start_time": "2025-06-30T16:14:12.405471Z"
    }
   },
   "source": [
    "#-- List of the tables to be loaded\n",
    "tables = [\"customer\", \"dwdate\", \"supplier\", \"part\", \"lineorder\"]\n",
    "\n",
    "#-- Insertion twice for each schema (WARNING!! EACH CAN TAKE MORE THAN 10 MINUTES!!!)\n",
    "nodistStats = loadTables(\"nodist\", tables)\n",
    "distStats = loadTables(\"dist\", tables)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= LOADING TABLE: ** customer ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "            copy customer from 's3://awssampledbuswest2/ssbgz/customer'\n",
      "            credentials 'aws_iam_role=arn:aws:iam::522814721929:role/myRedshiftRole'\n",
      "            gzip region 'us-west-2';\n",
      "        \n",
      "=== DONE IN: 16.13 sec\n",
      "\n",
      "======= LOADING TABLE: ** dwdate ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "            copy dwdate from 's3://awssampledbuswest2/ssbgz/dwdate'\n",
      "            credentials 'aws_iam_role=arn:aws:iam::522814721929:role/myRedshiftRole'\n",
      "            gzip region 'us-west-2';\n",
      "        \n",
      "=== DONE IN: 3.05 sec\n",
      "\n",
      "======= LOADING TABLE: ** supplier ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "            copy supplier from 's3://awssampledbuswest2/ssbgz/supplier'\n",
      "            credentials 'aws_iam_role=arn:aws:iam::522814721929:role/myRedshiftRole'\n",
      "            gzip region 'us-west-2';\n",
      "        \n",
      "=== DONE IN: 11.26 sec\n",
      "\n",
      "======= LOADING TABLE: ** part ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "            copy part from 's3://awssampledbuswest2/ssbgz/part'\n",
      "            credentials 'aws_iam_role=arn:aws:iam::522814721929:role/myRedshiftRole'\n",
      "            gzip region 'us-west-2';\n",
      "        \n",
      "=== DONE IN: 13.11 sec\n",
      "\n",
      "======= LOADING TABLE: ** lineorder ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "            copy lineorder from 's3://awssampledbuswest2/ssbgz/lineorder'\n",
      "            credentials 'aws_iam_role=arn:aws:iam::522814721929:role/myRedshiftRole'\n",
      "            gzip region 'us-west-2';\n",
      "        \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m tables \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdwdate\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msupplier\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpart\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlineorder\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#-- Insertion twice for each schema (WARNING!! EACH CAN TAKE MORE THAN 10 MINUTES!!!)\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m nodistStats \u001B[38;5;241m=\u001B[39m \u001B[43mloadTables\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnodist\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m distStats \u001B[38;5;241m=\u001B[39m loadTables(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdist\u001B[39m\u001B[38;5;124m\"\u001B[39m, tables)\n",
      "Cell \u001B[0;32mIn[13], line 17\u001B[0m, in \u001B[0;36mloadTables\u001B[0;34m(schema, tables)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(SQL_COPY)\n\u001B[1;32m     16\u001B[0m t0 \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m---> 17\u001B[0m \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mSQL_COPY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m loadTime \u001B[38;5;241m=\u001B[39m time()\u001B[38;5;241m-\u001B[39mt0\n\u001B[1;32m     19\u001B[0m loadTimes\u001B[38;5;241m.\u001B[39mappend(loadTime)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/redshift_connector/cursor.py:241\u001B[0m, in \u001B[0;36mCursor.execute\u001B[0;34m(self, operation, args, stream, merge_socket_read)\u001B[0m\n\u001B[1;32m    239\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_c\u001B[38;5;241m.\u001B[39mexecute(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin transaction\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_c\u001B[38;5;241m.\u001B[39mmerge_socket_read \u001B[38;5;241m=\u001B[39m merge_socket_read\n\u001B[0;32m--> 241\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/redshift_connector/core.py:1996\u001B[0m, in \u001B[0;36mConnection.execute\u001B[0;34m(self, cursor, operation, vals)\u001B[0m\n\u001B[1;32m   1994\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_messages_merge_socket_read(cursor)\n\u001B[1;32m   1995\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1996\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_messages\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/redshift_connector/core.py:2184\u001B[0m, in \u001B[0;36mConnection.handle_messages\u001B[0;34m(self, cursor)\u001B[0m\n\u001B[1;32m   2181\u001B[0m code \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   2183\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m code \u001B[38;5;241m!=\u001B[39m READY_FOR_QUERY:\n\u001B[0;32m-> 2184\u001B[0m     buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2186\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   2187\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_usock\u001B[38;5;241m.\u001B[39mtimeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/ssl.py:1274\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1273\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/ssl.py:1130\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Compare the load performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plotting of the timing results\n",
    "stats = distStats.join(nodistStats)\n",
    "stats.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Compare Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneDim_SQL =\"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select sum(lo_extendedprice*lo_discount) as revenue\n",
    "from lineorder, dwdate\n",
    "where lo_orderdate = d_datekey\n",
    "and d_year = 1997 \n",
    "and lo_discount between 1 and 3 \n",
    "and lo_quantity < 24;\n",
    "\"\"\"\n",
    "\n",
    "twoDim_SQL=\"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select sum(lo_revenue), d_year, p_brand1\n",
    "from lineorder, dwdate, part, supplier\n",
    "where lo_orderdate = d_datekey\n",
    "and lo_partkey = p_partkey\n",
    "and lo_suppkey = s_suppkey\n",
    "and p_category = 'MFGR#12'\n",
    "and s_region = 'AMERICA'\n",
    "group by d_year, p_brand1\n",
    "\"\"\"\n",
    "\n",
    "drill_SQL = \"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select c_city, s_city, d_year, sum(lo_revenue) as revenue \n",
    "from customer, lineorder, supplier, dwdate\n",
    "where lo_custkey = c_custkey\n",
    "and lo_suppkey = s_suppkey\n",
    "and lo_orderdate = d_datekey\n",
    "and (c_city='UNITED KI1' or\n",
    "c_city='UNITED KI5')\n",
    "and (s_city='UNITED KI1' or\n",
    "s_city='UNITED KI5')\n",
    "and d_yearmonth = 'Dec1997'\n",
    "group by c_city, s_city, d_year\n",
    "order by d_year asc, revenue desc;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "oneDimSameDist_SQL =\"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select lo_orderdate, sum(lo_extendedprice*lo_discount) as revenue  \n",
    "from lineorder, part\n",
    "where lo_partkey  = p_partkey\n",
    "group by lo_orderdate\n",
    "order by lo_orderdate\n",
    "\"\"\"\n",
    "\n",
    "def compareQueryTimes(schema):\n",
    "    queryTimes  =[] \n",
    "    for i,query in enumerate([oneDim_SQL, twoDim_SQL, drill_SQL, oneDimSameDist_SQL]):\n",
    "        t0 = time()\n",
    "        q = query.format(schema)\n",
    "        cur.execute(q)\n",
    "        queryTime = time()-t0\n",
    "        queryTimes.append(queryTime)\n",
    "    return pd.DataFrame({\"query\":[\"oneDim\",\"twoDim\", \"drill\", \"oneDimSameDist\"], \"queryTime_\"+schema:queryTimes}).set_index('query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noDistQueryTimes = compareQueryTimes(\"nodist\")\n",
    "distQueryTimes   = compareQueryTimes(\"dist\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryTimeDF =noDistQueryTimes.join(distQueryTimes)\n",
    "queryTimeDF.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvementDF = queryTimeDF[\"distImprovement\"] =100.0*(queryTimeDF['queryTime_nodist']-queryTimeDF['queryTime_dist'])/queryTimeDF['queryTime_nodist']\n",
    "improvementDF.plot.bar(title=\"% dist Improvement by query\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
