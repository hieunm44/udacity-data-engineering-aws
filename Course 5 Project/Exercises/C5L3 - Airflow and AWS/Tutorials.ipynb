{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Airflow and AWS",
   "id": "ae47725b14ad0dd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Tạo một IAM user trên AWS với 3 policies: `AdministratorAccess`, `AmazonRedshiftFullAccess`, `AmazonS3FullAccess`. Tạo Access key và lưu lại.\n",
    "2. Trong Airflow, vào **Admin** -> **Connections**. Tạo connection với AWS như ở dưới. \\\n",
    "   (Nhớ install package `apache-airflow-providers-amazon` bản mới nhất và đặt `test_connection = Enabled` trong file `airflow.cfg`)\n",
    "\n",
    "   <img src=\"images/aws1.png\" width=1500>\n",
    "\n",
    "3. Tạo S3 bucket và copy data vào\n",
    "   ```bash\n",
    "   aws s3 mb s3://nd027-hieu\n",
    "   aws s3 cp s3://udacity-dend/data-pipelines/ ~/data-pipelines/ --recursive\n",
    "   aws s3 cp ~/data-pipelines/ s3://nd027-hieu/data-pipelines/ --recursive\n",
    "   aws s3 ls s3://nd027-hieu/data-pipelines/\n",
    "   ```\n",
    "\n",
    "4. Trong Airflow, vào **Admin** -> **Variables**. Tạo các variables như ở dưới:\n",
    "\n",
    "   <img src=\"images/aws2.png\" width=1500>\n",
    "\n",
    "5. Xem hai files `ex1_sql_statements.py` và `ex2_connections_hooks.py`. Nhớ sửa lại tên S3 bucket. Chạy file `ex2_connections_hooks.py` trên Airflow, sẽ log các files ở trong S3 bucket trên. Chạy xong vào xem log file sẽ thấy."
   ],
   "id": "e678fc2612f59024"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "6. Tạo Redshift Role trên AWS\n",
    "   ```bash\n",
    "   aws iam create-role --role-name my-redshift-service-role --assume-role-policy-document '{\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"redshift.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }'\n",
    "   ```\n",
    "\n",
    "7. Cấp full access to S3 cho role vừa tạo\n",
    "   ```bash\n",
    "   aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --role-name my-redshift-service-role\n",
    "   ```\n",
    "\n",
    "8. Vào **Redshift** -> **Redshift Serverless** \\\n",
    "   Chọn **Customize settings**, điền admin và password. \\\n",
    "   Trong **Associated IAM roles**, Chọn **Associate IAM roles**, chọn `my-redshift-service-role`.\n",
    "   Tick **Turn on enhanced VPC routing**, còn lại để nguyên -> **Save configuration** \\\n",
    "   Vào Workgroup configuration để kiểm tra.\n",
    "\n",
    "   <img src=\"images/aws3.png\" width=1500>\n",
    "\n",
    "9. Ấn vào Workgroup vừa tạo. Trong phần **Network and security**, chọn **Edit**.\n",
    "\n",
    "   <img src=\"images/aws4.png\" width=1500>\n",
    "\n",
    "10. Tick **Turn on Publicly accessible** -> **Save changes**\n",
    "\n",
    "    <img src=\"images/aws5.png\" width=700>\n",
    "\n",
    "11. Ấn vào link ớ dưới **VPC security group**, sẽ đc đưa tới Security Groups trong EC2. \\\n",
    "    Ấn vào **Security group**, thêm một **Inboud rule**.\n",
    "\n",
    "    <img src=\"images/aws6.png\" width=1500>\n",
    "\n",
    "12. Tạo connection với Redshift trong Airflow\n",
    "\n",
    "    <img src=\"images/aws7.png\" width=1500>"
   ],
   "id": "b4237b7ae6beb199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "13. Xem file `ex3_s3_to_redshift.py`. Chạy file này trên Airflow, sẽ tạo một table `trips` trong Redshift -> Load data vào đó từ file `divvy_trips_2018.csv` trong S3 -> Tạo table `station_traffic`. \\\n",
    "    Lưu ý: Để import trực tiếp code từ một file khác (ở đây có `import sql_statement`), ko đc để các files trong subfolder ở folder `home/airflow/dags`. Nếu muốn để file trong subfolder, phải đặt tên subfolder ko có space, VD `c5l3`, và dùng `from c5l3 import sql_statements`.\n",
    "14. Vào worksgroup trên Redshift, ấn vào **Query data**, sẽ đc đưa tới **Query editor** trong Redshift.\n",
    "\n",
    "    <img src=\"images/aws8.png\" width=1500>\n",
    "\n",
    "15. Ấn vào dấu $>$ bên cạnh tên workgroup để kết nối tới DB.\n",
    "\n",
    "    <img src=\"images/aws9.png\" width=700>\n",
    "\n",
    "16. Để nguyên, ấn **Create connection**.\n",
    "\n",
    "    <img src=\"images/aws10.png\" width=400>\n",
    "\n",
    "17. Vào xem các tables đã tạo. Ấn chuột phải vào table \"station_traffic\" -> **Select table** -> **Run**\n",
    "\n",
    "    <img src=\"images/aws11.png\" width=1500>\n"
   ],
   "id": "dea31519a3e99cc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
